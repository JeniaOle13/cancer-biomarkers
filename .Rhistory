conf_matrix_list[[i]] <- conf_matrix
}
roc_combined <- roc_list[[1]]
for (i in 2:length(roc_list)) {
roc_combined <- roc_combined + roc_list[[i]]
}
roc_mean <- roc_combined / length(roc_list)
conf_metrics <- map_dfr(conf_matrix_list, ~{
data.frame(
Accuracy = .x$overall["Accuracy"],
Sensitivity = .x$byClass["Sensitivity"],
Specificity = .x$byClass["Specificity"]
)
}, .id = "Dataset") %>%
mutate(Dataset = unique_datasets[as.numeric(Dataset)])
mean(conf_metrics$Accuracy)
mean(conf_metrics$Sensitivity)
mean(conf_metrics$Specificity)
for (i in seq_along(unique_datasets)) {
test_dataset <- unique_datasets[i]
train_data <- df.log_ratio %>% filter(dataset != test_dataset)
test_data <- df.log_ratio %>% filter(dataset == test_dataset)
# Train logistic regression model
model <- glm(response ~ log_ratio, family = binomial, data = train_data, weights = weights)
# model <- glm(response ~ log_ratio, family = binomial, data = train_data)
# Predict on test data
test_data$pred_prob <- predict(model, test_data, type = "response")
roc_obj <- roc(test_data$response, test_data$pred_prob)
roc_list[[i]] <- roc_obj$specificities
# Confusion matrix (using 0.5 as threshold)
test_data$pred_class <- ifelse(test_data$pred_prob >= 0.5, 1, 0)
conf_matrix <- confusionMatrix(
as.factor(test_data$pred_class),
test_data$response,
positive = "1"
)
conf_matrix_list[[i]] <- conf_matrix
}
roc_combined <- roc_list[[1]]
for (i in 2:length(roc_list)) {
roc_combined <- roc_combined + roc_list[[i]]
}
roc_mean <- roc_combined / length(roc_list)
conf_metrics <- map_dfr(conf_matrix_list, ~{
data.frame(
Accuracy = .x$overall["Accuracy"],
Sensitivity = .x$byClass["Sensitivity"],
Specificity = .x$byClass["Specificity"]
)
}, .id = "Dataset") %>%
mutate(Dataset = unique_datasets[as.numeric(Dataset)])
mean(conf_metrics$Accuracy)
mean(conf_metrics$Sensitivity)
mean(conf_metrics$Specificity)
roc_mean
mean(conf_metrics$Sensitivity)
mean(conf_metrics$Specificity)
mean(conf_metrics$Accuracy)
#| include: false
df.log_ratio <- NULL
for (i in rownames(ogu_table)){
df <- ogu_table[rownames(ogu_table) %in% i,]
df_denominator <- df[colnames(df) %in% ogu.markers$featureid[ogu.markers$biomarker == "denominator"]]
df_numerator <- df[colnames(df) %in% ogu.markers$featureid[ogu.markers$biomarker == "numerator"]]
df_denominator <- df_denominator[df_denominator > 0]
df_numerator <- df_numerator[df_numerator > 0]
log_ratio <- log(sum(df_numerator)/sum(df_denominator))
df.s <- data.frame(sampleid = i, log_ratio)
df.log_ratio <- rbind(df.s, df.log_ratio)
}
df.log_ratio <- merge(df.log_ratio, meta_data, by = 1)
df.log_ratio <- df.log_ratio[df.log_ratio$log_ratio != Inf,]
df.log_ratio <- df.log_ratio[df.log_ratio$log_ratio != -Inf,]
#| include: false
logratio_boxplot <- ggplot(df.log_ratio, aes(response, log_ratio, col = response))+
stat_halfeye()+
xlab("Response")+
ylab("Log ratio")+
theme_pubr()+
theme(legend.position = "none")+
scale_color_brewer(palette = "Set1")
#| echo: false
#| fig-cap: Figure 3. Log ratio boxplot.
logratio_boxplot
#| echo: false
lmer.log_ratio <- lmer(log_ratio ~ response + (1|dataset), data=df.log_ratio)
df.log_ratio <- df.log_ratio |>  mutate(response = as.factor(ifelse(response == "R", 1, 0)))
df.log_ratio$dataset <- as.factor(df.log_ratio$dataset)
df.log_ratio$cancer_type <- as.factor(df.log_ratio$cancer_type)
unique_datasets <- unique(df.log_ratio$dataset)
roc_list <- list()
conf_matrix_list <- list()
class_counts <- table(df.log_ratio$response)
df.log_ratio$weights <- ifelse(df.log_ratio$response == "1",
1/class_counts["1"],
1/class_counts["0"])
df.log_ratio$rank <- rank(df.log_ratio$response)
for (i in seq_along(unique_datasets)) {
test_dataset <- unique_datasets[i]
train_data <- df.log_ratio %>% filter(dataset != test_dataset)
test_data <- df.log_ratio %>% filter(dataset == test_dataset)
# Train logistic regression model
model <- glm(response ~ log_ratio, family = binomial, data = train_data, weights = weights)
# model <- glm(response ~ log_ratio, family = binomial, data = train_data)
# Predict on test data
test_data$pred_prob <- predict(model, test_data, type = "response")
roc_obj <- roc(test_data$response, test_data$pred_prob)
roc_list[[i]] <- roc_obj$specificities
# Confusion matrix (using 0.5 as threshold)
test_data$pred_class <- ifelse(test_data$pred_prob >= 0.5, 1, 0)
conf_matrix <- confusionMatrix(
as.factor(test_data$pred_class),
test_data$response,
positive = "1"
)
conf_matrix_list[[i]] <- conf_matrix
}
roc_combined <- roc_list[[1]]
for (i in 2:length(roc_list)) {
roc_combined <- roc_combined + roc_list[[i]]
}
roc_mean <- roc_combined / length(roc_list)
conf_metrics <- map_dfr(conf_matrix_list, ~{
data.frame(
Accuracy = .x$overall["Accuracy"],
Sensitivity = .x$byClass["Sensitivity"],
Specificity = .x$byClass["Specificity"]
)
}, .id = "Dataset") %>%
mutate(Dataset = unique_datasets[as.numeric(Dataset)])
mean(conf_metrics$Accuracy)
mean(conf_metrics$Sensitivity)
mean(conf_metrics$Specificity)
df.log_ratio_centered <- df.log_ratio %>%
group_by(dataset) %>%
mutate(log_ratio_centered_group = log_ratio - mean(log_ratio, na.rm = TRUE)) %>%
ungroup()
df.log_ratio_centered
df.log_ratio_centered <- as.data.frame(df.log_ratio_centered)
df.log_ratio_centered
unique_datasets <- unique(df.log_ratio$dataset)
roc_list <- list()
conf_matrix_list <- list()
class_counts <- table(df.log_ratio$response)
df.log_ratio$weights <- ifelse(df.log_ratio$response == "1",
1/class_counts["1"],
1/class_counts["0"])
df.log_ratio$rank <- rank(df.log_ratio$response)
for (i in seq_along(unique_datasets)) {
test_dataset <- unique_datasets[i]
train_data <- df.log_ratio %>% filter(dataset != test_dataset)
test_data <- df.log_ratio %>% filter(dataset == test_dataset)
# Train logistic regression model
model <- glm(response ~ log_ratio, family = binomial, data = train_data, weights = weights)
# model <- glm(response ~ log_ratio, family = binomial, data = train_data)
# Predict on test data
test_data$pred_prob <- predict(model, test_data, type = "response")
roc_obj <- roc(test_data$response, test_data$pred_prob)
roc_list[[i]] <- roc_obj$specificities
# Confusion matrix (using 0.5 as threshold)
test_data$pred_class <- ifelse(test_data$pred_prob >= 0.5, 1, 0)
conf_matrix <- confusionMatrix(
as.factor(test_data$pred_class),
test_data$response,
positive = "1"
)
conf_matrix_list[[i]] <- conf_matrix
}
roc_combined <- roc_list[[1]]
for (i in 2:length(roc_list)) {
roc_combined <- roc_combined + roc_list[[i]]
}
roc_mean <- roc_combined / length(roc_list)
conf_metrics <- map_dfr(conf_matrix_list, ~{
data.frame(
Accuracy = .x$overall["Accuracy"],
Sensitivity = .x$byClass["Sensitivity"],
Specificity = .x$byClass["Specificity"]
)
}, .id = "Dataset") %>%
mutate(Dataset = unique_datasets[as.numeric(Dataset)])
mean(conf_metrics$Accuracy)
mean(conf_metrics$Sensitivity)
mean(conf_metrics$Specificity)
df.log_ratio_centered <- df.log_ratio %>%
group_by(dataset) %>%
mutate(log_ratio_centered = log_ratio - mean(log_ratio, na.rm = TRUE)) %>%
ungroup()
df.log_ratio_centered <- as.data.frame(df.log_ratio_centered)
for (i in seq_along(unique_datasets)) {
test_dataset <- unique_datasets[i]
train_data <- df.log_ratio_centered %>% filter(dataset != test_dataset)
test_data <- df.log_ratio_centered %>% filter(dataset == test_dataset)
# Train logistic regression model
model <- glm(response ~ log_ratio_centered, family = binomial, data = train_data, weights = weights)
# model <- glm(response ~ log_ratio, family = binomial, data = train_data)
# Predict on test data
test_data$pred_prob <- predict(model, test_data, type = "response")
roc_obj <- roc(test_data$response, test_data$pred_prob)
roc_list[[i]] <- roc_obj$specificities
# Confusion matrix (using 0.5 as threshold)
test_data$pred_class <- ifelse(test_data$pred_prob >= 0.5, 1, 0)
conf_matrix <- confusionMatrix(
as.factor(test_data$pred_class),
test_data$response,
positive = "1"
)
conf_matrix_list[[i]] <- conf_matrix
}
roc_combined <- roc_list[[1]]
for (i in 2:length(roc_list)) {
roc_combined <- roc_combined + roc_list[[i]]
}
roc_mean <- roc_combined / length(roc_list)
conf_metrics <- map_dfr(conf_matrix_list, ~{
data.frame(
Accuracy = .x$overall["Accuracy"],
Sensitivity = .x$byClass["Sensitivity"],
Specificity = .x$byClass["Specificity"]
)
}, .id = "Dataset") %>%
mutate(Dataset = unique_datasets[as.numeric(Dataset)])
mean(conf_metrics$Accuracy)
mean(conf_metrics$Sensitivity)
mean(conf_metrics$Specificity)
df.log_ratio_centered$rank <- rank(df.log_ratio_centered$log_ratio_centered)
for (i in seq_along(unique_datasets)) {
test_dataset <- unique_datasets[i]
train_data <- df.log_ratio_centered %>% filter(dataset != test_dataset)
test_data <- df.log_ratio_centered %>% filter(dataset == test_dataset)
# Train logistic regression model
model <- glm(response ~ rank, family = binomial, data = train_data, weights = weights)
# model <- glm(response ~ log_ratio, family = binomial, data = train_data)
# Predict on test data
test_data$pred_prob <- predict(model, test_data, type = "response")
roc_obj <- roc(test_data$response, test_data$pred_prob)
roc_list[[i]] <- roc_obj$specificities
# Confusion matrix (using 0.5 as threshold)
test_data$pred_class <- ifelse(test_data$pred_prob >= 0.5, 1, 0)
conf_matrix <- confusionMatrix(
as.factor(test_data$pred_class),
test_data$response,
positive = "1"
)
conf_matrix_list[[i]] <- conf_matrix
}
roc_combined <- roc_list[[1]]
for (i in 2:length(roc_list)) {
roc_combined <- roc_combined + roc_list[[i]]
}
roc_mean <- roc_combined / length(roc_list)
conf_metrics <- map_dfr(conf_matrix_list, ~{
data.frame(
Accuracy = .x$overall["Accuracy"],
Sensitivity = .x$byClass["Sensitivity"],
Specificity = .x$byClass["Specificity"]
)
}, .id = "Dataset") %>%
mutate(Dataset = unique_datasets[as.numeric(Dataset)])
mean(conf_metrics$Accuracy)
mean(conf_metrics$Sensitivity)
mean(conf_metrics$Specificity)
for (i in seq_along(unique_datasets)) {
test_dataset <- unique_datasets[i]
train_data <- df.log_ratio_centered %>% filter(dataset != test_dataset)
test_data <- df.log_ratio_centered %>% filter(dataset == test_dataset)
# Train logistic regression model
model <- glm(response ~ log_ratio_centered, family = binomial, data = train_data)
# model <- glm(response ~ log_ratio, family = binomial, data = train_data)
# Predict on test data
test_data$pred_prob <- predict(model, test_data, type = "response")
roc_obj <- roc(test_data$response, test_data$pred_prob)
roc_list[[i]] <- roc_obj$specificities
# Confusion matrix (using 0.5 as threshold)
test_data$pred_class <- ifelse(test_data$pred_prob >= 0.5, 1, 0)
conf_matrix <- confusionMatrix(
as.factor(test_data$pred_class),
test_data$response,
positive = "1"
)
conf_matrix_list[[i]] <- conf_matrix
}
roc_combined <- roc_list[[1]]
for (i in 2:length(roc_list)) {
roc_combined <- roc_combined + roc_list[[i]]
}
roc_mean <- roc_combined / length(roc_list)
conf_metrics <- map_dfr(conf_matrix_list, ~{
data.frame(
Accuracy = .x$overall["Accuracy"],
Sensitivity = .x$byClass["Sensitivity"],
Specificity = .x$byClass["Specificity"]
)
}, .id = "Dataset") %>%
mutate(Dataset = unique_datasets[as.numeric(Dataset)])
mean(conf_metrics$Accuracy)
mean(conf_metrics$Sensitivity)
mean(conf_metrics$Specificity)
df.log_ratio_centered <- df.log_ratio %>%
group_by(dataset) %>%
mutate(log_ratio_centered = log_ratio - (mean(log_ratio, na.rm = TRUE)/sd(log_ratio, na.rm = TRUE))) %>%
ungroup()
df.log_ratio_centered <- as.data.frame(df.log_ratio_centered)
unique_datasets <- unique(df.log_ratio$dataset)
roc_list <- list()
conf_matrix_list <- list()
class_counts <- table(df.log_ratio$response)
df.log_ratio$weights <- ifelse(df.log_ratio$response == "1",
1/class_counts["1"],
1/class_counts["0"])
df.log_ratio_centered$rank <- rank(df.log_ratio_centered$log_ratio_centered)
for (i in seq_along(unique_datasets)) {
test_dataset <- unique_datasets[i]
train_data <- df.log_ratio_centered %>% filter(dataset != test_dataset)
test_data <- df.log_ratio_centered %>% filter(dataset == test_dataset)
# Train logistic regression model
model <- glm(response ~ log_ratio_centered, family = binomial, data = train_data, weights = weights)
# model <- glm(response ~ log_ratio, family = binomial, data = train_data)
# Predict on test data
test_data$pred_prob <- predict(model, test_data, type = "response")
roc_obj <- roc(test_data$response, test_data$pred_prob)
roc_list[[i]] <- roc_obj$specificities
# Confusion matrix (using 0.5 as threshold)
test_data$pred_class <- ifelse(test_data$pred_prob >= 0.5, 1, 0)
conf_matrix <- confusionMatrix(
as.factor(test_data$pred_class),
test_data$response,
positive = "1"
)
conf_matrix_list[[i]] <- conf_matrix
}
roc_combined <- roc_list[[1]]
for (i in 2:length(roc_list)) {
roc_combined <- roc_combined + roc_list[[i]]
}
roc_mean <- roc_combined / length(roc_list)
conf_metrics <- map_dfr(conf_matrix_list, ~{
data.frame(
Accuracy = .x$overall["Accuracy"],
Sensitivity = .x$byClass["Sensitivity"],
Specificity = .x$byClass["Specificity"]
)
}, .id = "Dataset") %>%
mutate(Dataset = unique_datasets[as.numeric(Dataset)])
mean(conf_metrics$Accuracy)
mean(conf_metrics$Sensitivity)
mean(conf_metrics$Specificity)
df.log_ratio_centered <- df.log_ratio %>%
group_by(dataset) %>%
mutate(log_ratio_centered = log_ratio - median(log_ratio, na.rm = TRUE)) %>%
ungroup()
df.log_ratio_centered <- as.data.frame(df.log_ratio_centered)
unique_datasets <- unique(df.log_ratio$dataset)
roc_list <- list()
conf_matrix_list <- list()
class_counts <- table(df.log_ratio$response)
df.log_ratio$weights <- ifelse(df.log_ratio$response == "1",
1/class_counts["1"],
1/class_counts["0"])
df.log_ratio_centered$rank <- rank(df.log_ratio_centered$log_ratio_centered)
for (i in seq_along(unique_datasets)) {
test_dataset <- unique_datasets[i]
train_data <- df.log_ratio_centered %>% filter(dataset != test_dataset)
test_data <- df.log_ratio_centered %>% filter(dataset == test_dataset)
# Train logistic regression model
model <- glm(response ~ log_ratio_centered, family = binomial, data = train_data, weights = weights)
# model <- glm(response ~ log_ratio, family = binomial, data = train_data)
# Predict on test data
test_data$pred_prob <- predict(model, test_data, type = "response")
roc_obj <- roc(test_data$response, test_data$pred_prob)
roc_list[[i]] <- roc_obj$specificities
# Confusion matrix (using 0.5 as threshold)
test_data$pred_class <- ifelse(test_data$pred_prob >= 0.5, 1, 0)
conf_matrix <- confusionMatrix(
as.factor(test_data$pred_class),
test_data$response,
positive = "1"
)
conf_matrix_list[[i]] <- conf_matrix
}
roc_combined <- roc_list[[1]]
for (i in 2:length(roc_list)) {
roc_combined <- roc_combined + roc_list[[i]]
}
roc_mean <- roc_combined / length(roc_list)
conf_metrics <- map_dfr(conf_matrix_list, ~{
data.frame(
Accuracy = .x$overall["Accuracy"],
Sensitivity = .x$byClass["Sensitivity"],
Specificity = .x$byClass["Specificity"]
)
}, .id = "Dataset") %>%
mutate(Dataset = unique_datasets[as.numeric(Dataset)])
mean(conf_metrics$Accuracy)
mean(conf_metrics$Sensitivity)
mean(conf_metrics$Specificity)
for (i in seq_along(unique_datasets)) {
test_dataset <- unique_datasets[i]
train_data <- df.log_ratio_centered %>% filter(dataset != test_dataset)
test_data <- df.log_ratio_centered %>% filter(dataset == test_dataset)
# Train logistic regression model
model <- glm(response ~ log_ratio_centered, family = binomial, data = train_data)
# model <- glm(response ~ log_ratio, family = binomial, data = train_data)
# Predict on test data
test_data$pred_prob <- predict(model, test_data, type = "response")
roc_obj <- roc(test_data$response, test_data$pred_prob)
roc_list[[i]] <- roc_obj$specificities
# Confusion matrix (using 0.5 as threshold)
test_data$pred_class <- ifelse(test_data$pred_prob >= 0.5, 1, 0)
conf_matrix <- confusionMatrix(
as.factor(test_data$pred_class),
test_data$response,
positive = "1"
)
conf_matrix_list[[i]] <- conf_matrix
}
roc_combined <- roc_list[[1]]
for (i in 2:length(roc_list)) {
roc_combined <- roc_combined + roc_list[[i]]
}
roc_mean <- roc_combined / length(roc_list)
conf_metrics <- map_dfr(conf_matrix_list, ~{
data.frame(
Accuracy = .x$overall["Accuracy"],
Sensitivity = .x$byClass["Sensitivity"],
Specificity = .x$byClass["Specificity"]
)
}, .id = "Dataset") %>%
mutate(Dataset = unique_datasets[as.numeric(Dataset)])
mean(conf_metrics$Accuracy)
mean(conf_metrics$Sensitivity)
mean(conf_metrics$Specificity)
for (i in seq_along(unique_datasets)) {
test_dataset <- unique_datasets[i]
train_data <- df.log_ratio_centered %>% filter(dataset != test_dataset)
test_data <- df.log_ratio_centered %>% filter(dataset == test_dataset)
# Train logistic regression model
model <- glm(response ~ log_ratio_centered, family = binomial, data = train_data, weights = weights)
# model <- glm(response ~ log_ratio, family = binomial, data = train_data)
# Predict on test data
test_data$pred_prob <- predict(model, test_data, type = "response")
roc_obj <- roc(test_data$response, test_data$pred_prob)
roc_list[[i]] <- roc_obj$specificities
# Confusion matrix (using 0.5 as threshold)
test_data$pred_class <- ifelse(test_data$pred_prob >= 0.5, 1, 0)
conf_matrix <- confusionMatrix(
as.factor(test_data$pred_class),
test_data$response,
positive = "1"
)
conf_matrix_list[[i]] <- conf_matrix
}
roc_combined <- roc_list[[1]]
for (i in 2:length(roc_list)) {
roc_combined <- roc_combined + roc_list[[i]]
}
roc_mean <- roc_combined / length(roc_list)
conf_metrics <- map_dfr(conf_matrix_list, ~{
data.frame(
Accuracy = .x$overall["Accuracy"],
Sensitivity = .x$byClass["Sensitivity"],
Specificity = .x$byClass["Specificity"]
)
}, .id = "Dataset") %>%
mutate(Dataset = unique_datasets[as.numeric(Dataset)])
mean(conf_metrics$Accuracy)
mean(conf_metrics$Sensitivity)
mean(conf_metrics$Specificity)
fgsea_phylum <- GSEA(vec, TERM2GENE = ogu.markers[c(8,1)], eps = 0)
vec <- ogu.markers$mean
names(vec) <- ogu.markers$featureid
vec <- sort(vec, decreasing = T)
fgsea_phylum <- GSEA(vec, TERM2GENE = ogu.markers[c(8,1)], eps = 0)
fgsea_phylum_df <- as.data.frame(fgsea_phylum)
gseaNb(object = fgsea_phylum,
geneSetID = fgsea_phylum_df$ID,
curveCol = brewer.pal(name = "Set1", n = 9))
gseaNb(object = fgsea_class,
geneSetID = fgsea_class_df$ID,
curveCol = brewer.pal(name = "Set1", n = 9))
fgsea_phylum <- GSEA(vec, TERM2GENE = ogu.markers[c(8,1)], eps = 0)
fgsea_phylum_df <- as.data.frame(fgsea_phylum)
fgsea_class <- GSEA(vec, TERM2GENE = ogu.markers[c(9,1)], eps = 0)
fgsea_class_df <- as.data.frame(fgsea_class)
fgsea_order <- GSEA(vec, TERM2GENE = ogu.markers[c(10,1)], eps = 0)
fgsea_order_df <- as.data.frame(fgsea_order)
fgsea_family <- GSEA(vec, TERM2GENE = ogu.markers[c(11,1)], eps = 0)
fgsea_family_df <- as.data.frame(fgsea_family)
fgsea_genus <- GSEA(vec, TERM2GENE = ogu.markers[c(12,1)], eps = 0)
fgsea_genus_df <- as.data.frame(fgsea_genus)
gs_species <- ogu.markers[c(13,1)]
gs_species$species <- sub(" ", "_", gs_species$species)
fgsea_species <- GSEA(vec, TERM2GENE = ogu.markers[c(13,1)], eps = 0)
fgsea_species_df <- as.data.frame(fgsea_species)
gseaNb(object = fgsea_genus,
geneSetID = fgsea_genus_df$ID,
curveCol = c(brewer.pal(name = "Set1", n = 9)[-6], "cyan4"))
fgsea_food <- GSEA(vec, TERM2GENE = food[c(2,1)])
fgsea_bodysite <- GSEA(vec, TERM2GENE = body_site[c(2,1)])
gseaNb(object = fgsea_phylum,
geneSetID = fgsea_phylum_df$ID,
curveCol = brewer.pal(name = "Set1", n = 9))
fgsea_food <- GSEA(vec, TERM2GENE = food[c(2,1)])
fgsea_bodysite <- GSEA(vec, TERM2GENE = body_site[c(2,1)])
gseaNb(object = fgsea_food,
geneSetID = 'food',
htCol = c("#A50F15", "#08519C"))
gseaNb(object = fgsea_bodysite,
geneSetID = 'Oral cavity',
htCol = c("#A50F15", "#08519C"))
packageVersion("effectsize")
packageVersion("vegan")
